---
title: "TSA: Forecasting Competition"
author: "Hannah Schofield & Sebrina Zu"
output: pdf_document
always_allow_html: true
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: sentence
---
```{r package, message=FALSE, warning=FALSE}
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(zoo)
library(kableExtra)
library(xlsx)
```

```{r}
#Loading data
library(readxl)
load <- read_excel("Competition/Data/load.xlsx")
relative_humidity <- read_excel("Competition/Data/relative_humidity.xlsx")
temperature<-read_excel("Competition/Data/temperature.xlsx")
```

```{r}
#convert hourly to daily averages 
load_daily <- load %>% 
  mutate(daily_average=rowMeans(load[,3:26]))  %>% 
  select(date, daily_average)

```

```{r}
par(mfrow=c(1,2))
ACF_Plot <- Acf(load_daily$daily_average, lag = 40, plot = TRUE,main="")
PACF_Plot <- Pacf(load_daily$daily_average, lag = 40, plot = TRUE,main="")
par(mfrow=c(1,1))

```

```{r} 
#convert to time series 
ts_avgDaily <- msts(load_daily$daily_average, 
                           seasonal.periods =c(7,365.25),
                           start=c(2005,1,1))

```

```{r}
#create test and train data subsets for forecasting
n_for = 365
ts_avgDaily_train <- subset(ts_avgDaily,end = length(ts_avgDaily)-n_for)

ts_avgDaily_test <- subset(ts_avgDaily,start = length(ts_avgDaily)-n_for)

autoplot(ts_avgDaily_train)
autoplot(ts_avgDaily_test)

```

```{r ETS}
ETS_fit <-  stlf(ts_avgDaily_train,h=365)

#Plot foresting results
autoplot(ETS_fit) + ylab("Load")

#Plot model + observed data
autoplot(ts_avgDaily) +
  autolayer(ETS_fit, series="STL + ETS",PI=FALSE) +
  ylab("Load")
```

```{r ARIMA}

ARIMA_Four_fit <- auto.arima(ts_avgDaily_train, 
                             seasonal=TRUE, 
                             lambda=0,
                             xreg=fourier(ts_avgDaily_train, 
                                          K=c(2,12)))

#Forecast with ARIMA fit
#also need to specify h for fourier terms
ARIMA_Four_for <- forecast(ARIMA_Four_fit,
                           xreg=fourier(ts_avgDaily_train,
                                        K=c(2,12),
                                        h=365),
                                        h=365) 

#Plot foresting results
autoplot(ARIMA_Four_for) + ylab("Load")

#Plot model + observed data
autoplot(ts_avgDaily) +
  autolayer(ARIMA_Four_for, series="ARIMA_FOURIER",PI=FALSE) +
  ylab("Load")

```

```{r NN}
#NN_fit <- nnetar(ts_avgDaily_train,p=1,P=1)
NN_fit <- nnetar(ts_avgDaily_train,p=1,P=0,xreg=fourier(ts_avgDaily_train, K=c(2,12)))

#NN_for <- forecast(NN_fit, h=365) 
NN_for <- forecast(NN_fit, h=365,xreg=fourier(ts_avgDaily_train, K=c(2,12),h=365))

#Plot foresting results
autoplot(NN_for) +
  ylab("Load") 

#Plot model + observed data
autoplot(ts_avgDaily) +
  autolayer(NN_for, series="Neural Network",PI=FALSE)+
  ylab("Load") 


```

```{r TBATS}
# TBATS can take time to fit
TBATS_fit <- tbats(ts_avgDaily_train)

TBATS_for <- forecast(TBATS_fit, h=n_for)

#Plot foresting results
autoplot(TBATS_for) +
  ylab("Load") 

#Plot model + observed data
autoplot(ts_avgDaily) +
  autolayer(TBATS_for, series="TBATS",PI=FALSE)+
  ylab("Load") 

```

```{r SARIMA}
SARIMA_autofit <- auto.arima(ts_avgDaily_train)

SARIMA_for <- forecast(SARIMA_autofit,h=n_for)

#Plot foresting results
autoplot(SARIMA_for) +
  ylab("Load") 

#Plot model + observed data
autoplot(ts_avgDaily) +
  autolayer(SARIMA_for, series="SARIMA",PI=FALSE)+
  ylab("Load") 
```

```{r SSES}
SSES_seas <- es(ts_avgDaily_train,h=n_for,holdout=FALSE)

SS_seas <- StructTS(ts_avgDaily_train,
                    type="BSM",fixed=c(0,0.001,0.3,NA)) 
```


```{r scores}
#Model 1: STL + ETS
ETS_scores <- accuracy(ETS_fit$mean,ts_avgDaily_test)  

#Model 2: ARIMA + Fourier 
ARIMA_scores <- accuracy(ARIMA_Four_for$mean,ts_avgDaily_test)

# Model 3:  Neural Network 
NN_scores <- accuracy(NN_for$mean,ts_avgDaily_test)

## Model 4:  TBATS 
TBAT_scores <- accuracy(TBATS_for$mean,ts_avgDaily_test)

# Model 5:  SARIMA 
SARIMA_scores <- accuracy(SARIMA_for$mean,ts_avgDaily_test)

# Model 6:  SSES
SSES_scores <- accuracy(SSES_seas$forecast,ts_avgDaily_test)

# Model 7:  BSM 
SS_scores <- accuracy(SS_for$mean,ts_avgDaily_test)

```


```{r RMSE}
#create data frame
scores <- as.data.frame(
  rbind(ETS_scores, ARIMA_scores, NN_scores))
#, NN_scores, TBAT_scores))
row.names(scores) <- c("STL+ETS", "ARIMA+Fourier", "NN")

#choose model with lowest RMSE
best_model_index <- which.min(scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(scores[best_model_index,]))  

```

```{r compare}
autoplot(ts_avgDaily_test) +
  autolayer(ETS_fit, PI=FALSE, series="STL+ETS") +
  autolayer(ARIMA_Four_for, PI=FALSE, series="ARIMA + Fourier") +
  autolayer(NN_for,PI=FALSE, series="NN") +
  ylab("Daily Load") +
  guides(colour=guide_legend(title="Forecast"))

```

```{r}
#convert to submission format 

forecastRange <- seq(as.Date("2011-01-01"), as.Date("2011-02-28"), by="days")
forecastDat<- ARIMA_Four_for$mean[1:59]

submission <- data.frame(forecastRange, forecastDat)
write.xlsx(submission, file = "submission_schofield_zu4.xlsx")

```

```{r}
#convert to submission format 

forecastDat2 <- ETS_fit$mean[1:59]

submission2 <- data.frame(forecastRange,forecastDat2)
submission2

write.xlsx(submission2, file = "submission_schofield_zu3.xlsx")

```
```

